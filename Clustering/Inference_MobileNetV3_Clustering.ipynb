{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","collapsed_sections":["3Xnx6cHSSa1E","zlW5QVV7xhrg"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"x9cduLOoSNQ5"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import sklearn\n","from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n","from sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix, classification_report\n","from keras.callbacks import EarlyStopping\n","import matplotlib.pylab as plt\n","import os\n","from keras.models import Sequential, Model\n","from keras.layers import Input, Dense, Dropout, Flatten, ConvLSTM2D, TimeDistributed, Bidirectional, LSTM\n","from keras.utils import Sequence\n","from tensorflow.keras.callbacks import Callback\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","\n","class InferenceTimeCallback(Callback):\n","    def on_predict_batch_begin(self, batch, logs=None):\n","        self.start_time = time.time()\n","\n","    def on_predict_batch_end(self, batch, logs=None):\n","        self.end_time = time.time()\n","        self.inference_time = self.end_time - self.start_time\n","        print(f\"Inference time for batch {batch}: {self.inference_time} seconds\")\n"]},{"cell_type":"code","source":["# Mounts drive Google\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"metadata":{"id":"buNkoH5p0MG5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install codecarbon"],"metadata":{"id":"BQtXpnDgJEoc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Test sui tempi di inferenza per l'ultimo split sul modello ConvLSTM**\n","\n","\n","Partenza: clusterizzazione a 16 cluster con inizializzazione lineare dei centroidi\n","\n","Prove effettuate, tale prove sono state effettuate senza \"ripulire\" il modello da pesi ed informazioni extra derivanti dalla clusterizzazione(indici centroidi, ...):\n","\n","\n","*   **8 Cluster e centroidi a densità**: Accuratezza = 96.1%, AUC = 99.6%, tempo medio inferenza a batch = 0.42 s, peso: 28.6 MB, consumo energetico per 102 secondi di video: 0.00123 KW/h\n","\n","*   **8 Cluster e centroidi linear**: Accuratezza = 95%, AUC = 99.5%, tempo medio inferenza a batch = 0.41 s, peso: 28.6 MB, consumo energetico per 102 secondi di video: 0.0016 KW/h\n","\n","*   **8 Cluster e centroidi random**: Accuratezza = 93.4%, AUC = 99.3%, tempo medio inferenza a batch = 0.41 s, peso: 28.6 MB, consumo energetico per 102 secondi di video: 0.0023 KW/h\n","\n","*   **8 Cluster e centroidi Kmeans++**: Accuratezza = 95.6%, AUC = 99.6%, tempo medio inferenza a batch = 0.45 s, peso: 28.6 MB, consumo energetico per 102 secondi di video: 0.00162 KW/h\n","\n","*   **16 Cluster e centroide a densità**: Accuratezza = 96.1%, AUC = 99.6%, tempo medio inferenza a batch = 0.59 s, peso: 28,6 MB, consumo energetico per 102 secondi di video: 0.0019 KW/h\n","\n","*   **16 Cluster e centroidi linear**: Accuratezza = 95%, AUC = 99.5%, tempo medio inferenza a batch = 0.42 s, peso: 28,6 MB, consumo energetico per 102 secondi di video: 0.00086 KW/h\n","\n","*   **16 Cluster e centroidi random**: Accuratezza = 95%, AUC = 99.46%, tempo medio inferenza a batch = 0.4 s, peso: 28.6 MB, consumo energetico per 102 secondi di video: 0.0012 KW/h\n","\n","*   **16 Cluster e centroidi Kmeans++**: Accuratezza = 95%, AUC = 99.5%, tempo medio inferenza a batch = 0.42 s, peso: 28.6 MB, consumo energetico per 102 secondi di video: 0.00197 KW/h\n","\n","*   **32 Cluster e centroidi a densità**: Accuratezza = 95.6%, AUC = 99.6%, tempo medio inferenza a batch = 0.4 s, peso: 28.6 MB, consumo energetico per 102 secondi di video: 0.0014 KW/h\n","\n","*   **32 Cluster e centroidi linear**: Accuratezza = 95.6%, AUC = 99.6%, tempo medio inferenza a batch = 0.43 s, peso: 28.6 MB, consumo energetico per 102 secondi di video: 0.0023 KW/h\n","\n","*   **32 Cluster e centroidi random**: Accuratezza = 95%, AUC = 99.5%, tempo medio inferenza a batch = 0.33 s, peso: 28.6 MB, consumo energetico per 102 secondi di video: 0.00092 KW/h\n","\n","*   **32 Cluster e centroidi Kmeans++**: Accuratezza = 95.6%, AUC = 99.55%, tempo medio inferenza a batch = 0.45 s, peso: 28.6 MB, consumo energetico per 102 secondi di video: 0.0012 KW/h\n","\n"],"metadata":{"id":"3Xnx6cHSSa1E"}},{"cell_type":"code","source":["\n","from tensorflow.keras.models import load_model\n","\n","MobileNetV3Small_ConvLSTM= load_model('/content/gdrive/MyDrive/Modelli/MobileNet_V3_Small/ConvLSTM/final_model_fold_5.h5')\n","\n","\n","MobileNetV3Small_ConvLSTM.summary()\n"],"metadata":{"id":"pkaGvajDSzLr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","\n","\n","\n","for layer in MobileNetV3Small_ConvLSTM.layers:\n","    weights = layer.get_weights()\n","    if weights:\n","        plt.figure(figsize=(8, 6))\n","        for i, w in enumerate(weights):\n","            plt.hist(w.flatten(), bins=50, alpha=0.7, color='blue')\n","\n","        if 'time_distributed' in layer.name:\n","            plt.xlim(-100, 100)\n","\n","        plt.title(f'Disribuzione dei pesi per {layer.name}')\n","        plt.xlabel('Valore dei pesi')\n","        plt.ylabel('Frequenza')\n","        plt.grid(True)\n","        plt.tight_layout()\n","        plt.show()\n","\n","\n","\n"],"metadata":{"id":"aLECZw1j3a9t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import numpy as np\n","\n","\n","layer_names = []\n","weight_counts = []\n","mean_weights = []\n","\n","\n","for layer in MobileNetV3Small_ConvLSTM.layers:\n","    weights = layer.get_weights()\n","    if weights:\n","        total_weights = sum(w.size for w in weights)\n","        mean_weight = sum(w.mean() for w in weights) / len(weights)\n","        layer_names.append(layer.name)\n","        weight_counts.append(total_weights)\n","        mean_weights.append(mean_weight)\n","\n","\n","fig, ax = plt.subplots(figsize=(10, 8))\n","wedges, texts, autotexts = ax.pie(weight_counts, labels=layer_names, autopct='%1.1f%%', textprops={'weight': 'bold'})\n","\n","\n","legend_labels = [f'{layer_names[i]}: {mean_weights[i]:.2f}' for i in range(len(layer_names))]\n","ax.legend(wedges, legend_labels, title='Layer e Media Pesi', loc='upper right', bbox_to_anchor=(0,1,0,0))\n","\n","plt.title('Distribuzione dei pesi per ciascun layer')\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"C8DoieXRM4Ed"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","import tensorflow as tf\n","\n","\n","for layer in MobileNetV3Small_ConvLSTM.layers:\n","    weights = layer.get_weights()\n","    if weights:\n","        print(f\"Layer: {layer.name}\")\n","        for i, weight in enumerate(weights):\n","            print(f\"  Weight {i}: shape={weight.shape}, dtype={weight.dtype}\")\n"],"metadata":{"id":"oA-P5sKS6XFV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install tensorflow-model-optimization"],"metadata":{"id":"qnPMQQ1TwAjT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","import tensorflow as tf\n","import tensorflow_model_optimization as tfmot\n","from tensorflow import keras\n","\n","cluster_weights = tfmot.clustering.keras.cluster_weights\n","CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n","\n","NUM_CLUSTER = 32\n","clustering_params = {\n","  'number_of_clusters': NUM_CLUSTER,\n","  'cluster_centroids_init': CentroidInitialization.KMEANS_PLUS_PLUS\n","}\n","\n","\n","def custom_cluster_weights(layer):\n","    if isinstance(layer, keras.layers.ConvLSTM2D):\n","        return layer\n","    else:\n","        return cluster_weights(layer, **clustering_params)\n","\n","clustered_model = keras.models.clone_model(\n","    MobileNetV3Small_ConvLSTM,\n","    clone_function=custom_cluster_weights\n",")\n","\n","opt = keras.optimizers.Adam(learning_rate=1e-5)\n","\n","clustered_model.compile(\n","  loss=keras.losses.BinaryCrossentropy(),\n","  optimizer=opt,\n","  metrics=['accuracy'])\n","\n","clustered_model.save(\"/content/gdrive/My Drive/Modelli/MobileNet_V3_Small/Clusterizzazione/ConvLSTM/clustered_model_ConvLSTM_32Kmeans.h5\")\n","\n","clustered_model.summary()\n"],"metadata":{"id":"8PUQlJLyPR-H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","import os\n","import numpy as np\n","import cv2\n","import tensorflow as tf\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, accuracy_score, precision_score, recall_score\n","import matplotlib.pyplot as plt\n","import time\n","\n","\n","def preprocess_video(video_path, input_shape, batch_size):\n","    cap = cv2.VideoCapture(video_path)\n","    frames = []\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        frame = cv2.resize(frame, (input_shape[1], input_shape[0]))\n","        frame = frame.astype('float32')\n","        frames.append(frame)\n","\n","    cap.release()\n","    frames = np.array(frames)\n","\n","\n","    if len(frames) >= batch_size:\n","        num_batches = len(frames) // batch_size\n","        frames = frames[:num_batches * batch_size]\n","        batches = np.split(frames, num_batches)\n","    else:\n","        batches = []\n","\n","    return batches\n","\n","\n","def load_videos_from_folder(folder_path, label, input_shape, batch_size):\n","    videos = []\n","    labels = []\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith(\".mp4\") or filename.endswith(\".avi\"):\n","            video_path = os.path.join(folder_path, filename)\n","            video_batches = preprocess_video(video_path, input_shape, batch_size)\n","            videos.extend(video_batches)\n","            labels.extend([label] * len(video_batches))\n","    return videos, labels\n","\n","\n","def fine_tune_model_with_videos(model, train_folder_violence, train_folder_nonviolence, input_shape, batch_size, epochs, validation_split=0.1):\n","    violence_videos, violence_labels = load_videos_from_folder(train_folder_violence, 1, input_shape, batch_size)\n","    nonviolence_videos, nonviolence_labels = load_videos_from_folder(train_folder_nonviolence, 0, input_shape, batch_size)\n","\n","\n","    print(f'Number of violence video batches: {len(violence_videos)}')\n","    print(f'Number of non-violence video batches: {len(nonviolence_videos)}')\n","\n","    all_videos = np.concatenate((violence_videos, nonviolence_videos), axis=0)\n","    all_labels = np.concatenate((violence_labels, nonviolence_labels), axis=0)\n","\n","    print(f'Number of total video batches: {len(all_videos)}')\n","    print(f'Number of total labels: {len(all_labels)}')\n","\n","    model.fit(\n","        all_videos,\n","        all_labels,\n","        batch_size=batch_size,\n","        epochs=epochs,\n","        validation_split=validation_split\n","    )\n","\n","    return model, all_videos, all_labels\n","\n","model_path = '/content/gdrive/My Drive/Modelli/MobileNet_V3_Small/Clusterizzazione/ConvLSTM/clustered_model_ConvLSTM_32Kmeans.h5'\n","train_folder_violence = '/content/gdrive/MyDrive/Dataset/Data_Augmented/Violence'\n","train_folder_nonviolence = '/content/gdrive/MyDrive/Dataset/Data_Augmented/NonViolence'\n","input_shape = (224, 224)\n","sequence_length = 16\n","batch_size = 16\n","epochs = 1\n","\n","\n","model, all_videos, all_labels = fine_tune_model_with_videos(clustered_model, train_folder_violence, train_folder_nonviolence, input_shape, batch_size, epochs)\n","\n","model.save('/content/gdrive/My Drive/Modelli/MobileNet_V3_Small/Clusterizzazione/ConvLSTM/clustered_tuned_model_ConvLSTM_32Kmeans.h5')\n"],"metadata":{"id":"JfBB2sPU3tja"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","for layer in model.layers:\n","    weights = layer.get_weights()\n","    if weights:\n","        plt.figure(figsize=(8, 6))\n","        for i, w in enumerate(weights):\n","            plt.hist(w.flatten(), bins=50, alpha=0.7, color='blue')\n","\n","        if 'time_distributed' in layer.name:\n","            plt.xlim(-100, 100)\n","\n","        plt.title(f'Disribuzione dei pesi per {layer.name} , cluster settati: {NUM_CLUSTER}')\n","        plt.xlabel('Valore dei pesi')\n","        plt.ylabel('Frequenza')\n","        plt.grid(True)\n","        plt.tight_layout()\n","        plt.show()\n"],"metadata":{"id":"QlzDT4PqXDNP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","import os\n","import numpy as np\n","import cv2\n","import tensorflow as tf\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, accuracy_score, precision_score, recall_score\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import load_model\n","import time\n","\n","def load_keras_model(model_path):\n","    model = load_model(model_path)\n","    return model\n","\n","def preprocess_video(video_path, input_shape, batch_size):\n","    cap = cv2.VideoCapture(video_path)\n","    frames = []\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        frame = cv2.resize(frame, (input_shape[1], input_shape[0]))\n","        frame = frame.astype('float32') #/ 255.0\n","        frames.append(frame)\n","\n","    cap.release()\n","    frames = np.array(frames)\n","\n","\n","    if len(frames) >= batch_size:\n","        num_batches = len(frames) // batch_size\n","        frames = frames[:num_batches * batch_size]\n","        batches = np.split(frames, num_batches)\n","    else:\n","\n","        batches = []\n","\n","    return batches\n","\n","def run_inference(model, input_data):\n","    output_data = model.predict(input_data)\n","    return output_data\n","\n","def calculate_metrics(y_true, y_pred, y_probs):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    specificity = recall_score(y_true, y_pred, pos_label=0)\n","    fpr, tpr, thresholds = roc_curve(y_true, y_probs)\n","    roc_auc = auc(fpr, tpr)\n","\n","    return accuracy, precision, recall, specificity, roc_auc, fpr, tpr\n","\n","def plot_roc_curve(fpr, tpr, roc_auc, title='ROC Curve'):\n","    plt.figure()\n","    plt.plot(fpr, tpr, color='b', lw=2, label='ROC curve (area = %0.4f)' % roc_auc)\n","    plt.plot([0, 1], [0, 1], color='r', linestyle='--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title(title)\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","def load_videos_from_folder(folder_path, label, input_shape, batch_size):\n","    videos = []\n","    labels = []\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith(\".mp4\") or filename.endswith(\".avi\"):\n","            video_path = os.path.join(folder_path, filename)\n","            video_batches = preprocess_video(video_path, input_shape, batch_size)\n","            videos.extend(video_batches)\n","            labels.extend([label] * len(video_batches))\n","    return videos, labels\n","\n","from codecarbon import track_emissions\n","@track_emissions(project_name=\"MV3_Small_Inference_ConvLSTM_quantizzato_Float_pruned\")\n","def inferenceV3_ConvLSTM_Clusterizzata():\n","    violence_path = '/content/gdrive/MyDrive/VideoInferenza/Violence'\n","    nonviolence_path = '/content/gdrive/MyDrive/VideoInferenza/NonViolence'\n","    input_shape = (224, 224)\n","    batch_size = 16\n","\n","\n","    violence_videos, violence_labels = load_videos_from_folder(violence_path, 1, input_shape, batch_size)\n","    nonviolence_videos, nonviolence_labels = load_videos_from_folder(nonviolence_path, 0, input_shape, batch_size)\n","\n","    all_videos = violence_videos + nonviolence_videos\n","    all_labels = violence_labels + nonviolence_labels\n","\n","    all_videos = np.array([np.expand_dims(video, axis=0) for video in all_videos])\n","    all_labels = np.array(all_labels)\n","\n","    total_inference_time = 0\n","    y_probs = []\n","    for video in all_videos:\n","        start_time = time.time()\n","        output_data = run_inference(model, video)\n","        end_time = time.time()\n","        inference_time = end_time - start_time\n","        total_inference_time += inference_time\n","        y_probs.append(output_data.ravel()[0])\n","\n","    y_probs = np.array(y_probs)\n","    y_pred = np.round(y_probs)\n","\n","\n","    accuracy, precision, recall, specificity, roc_auc, fpr, tpr = calculate_metrics(all_labels, y_pred, y_probs)\n","\n","\n","    average_inference_time_per_batch = total_inference_time / len(all_videos)\n","\n","\n","    print(f'Accuracy: {accuracy:.4f}')\n","    print(f'Precision: {precision:.4f}')\n","    print(f'Recall: {recall:.4f}')\n","    print(f'Specificity: {specificity:.4f}')\n","    print(f'ROC AUC: {roc_auc:.4f}')\n","    print(f'Average Inference Time per Batch: {average_inference_time_per_batch:.4f} seconds')\n","\n","\n","    print('Classification Report:')\n","    print(classification_report(all_labels, y_pred, target_names=['NonViolent', 'Violent']))\n","\n","    print('Confusion Matrix:')\n","    print(confusion_matrix(all_labels, y_pred))\n","\n","\n","    plot_roc_curve(fpr, tpr, roc_auc, title='ROC Curve for tf_model_mv3_convLStm')\n","\n","if __name__ == '__main__':\n","    inferenceV3_ConvLSTM_Clusterizzata()\n"],"metadata":{"id":"Jw8rIiALMxZD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tempfile\n","\n","\n","final_model = tfmot.clustering.keras.strip_clustering(clustered_model)\n","\n","clustered_keras_file = tempfile.mkstemp('.h5')\n","print('Saving clustered model to: ', clustered_keras_file)\n","keras.models.save_model(final_model, clustered_keras_file,\n","                           include_optimizer=False)\n","\n","\n","clustered_tflite_file = '/content/gdrive/My Drive/Modelli/MobileNet_V3_Small/Clusterizzazione/ConvLSTM/final_clustered_model.tflite'\n","converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n","\n","converter.target_spec.supported_ops = [\n","    tf.lite.OpsSet.TFLITE_BUILTINS,\n","    tf.lite.OpsSet.SELECT_TF_OPS\n","]\n","\n","\n","converter._experimental_lower_tensor_list_ops = False\n","\n","tflite_clustered_model = converter.convert()\n","with open(clustered_tflite_file, 'wb') as f:\n","  f.write(tflite_clustered_model)\n","print('Saved clustered TFLite model to:', clustered_tflite_file)\n"],"metadata":{"id":"Cs4oaraEUULn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import tensorflow as tf\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, accuracy_score, precision_score, recall_score\n","import matplotlib.pyplot as plt\n","import time\n","\n","def load_tflite_model(model_path):\n","    interpreter = tf.lite.Interpreter(model_path=model_path)\n","    interpreter.allocate_tensors()\n","    return interpreter\n","\n","def run_inference(interpreter, input_data):\n","    input_details = interpreter.get_input_details()\n","    output_details = interpreter.get_output_details()\n","\n","    interpreter.set_tensor(input_details[0]['index'], input_data)\n","\n","\n","    start_time = time.time()\n","    interpreter.invoke()\n","    end_time = time.time()\n","    inference_time = end_time - start_time\n","\n","    output_data = interpreter.get_tensor(output_details[0]['index'])\n","\n","    return output_data, inference_time\n","\n","def calculate_metrics(y_true, y_pred, y_probs):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    specificity = recall_score(y_true, y_pred, pos_label=0)\n","    fpr, tpr, thresholds = roc_curve(y_true, y_probs)\n","    roc_auc = auc(fpr, tpr)\n","\n","    return accuracy, precision, recall, specificity, roc_auc, fpr, tpr\n","\n","def plot_roc_curve(fpr, tpr, roc_auc, title='ROC Curve'):\n","    plt.figure()\n","    plt.plot(fpr, tpr, color='b', lw=2, label='ROC curve (area = %0.4f)' % roc_auc)\n","    plt.plot([0, 1], [0, 1], color='r', linestyle='--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title(title)\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","def load_videos_from_folder(folder_path, label, input_shape, batch_size):\n","    videos = []\n","    labels = []\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith(\".mp4\") or filename.endswith(\".avi\"):\n","            video_path = os.path.join(folder_path, filename)\n","            video_batches = preprocess_video(video_path, input_shape, batch_size)\n","            videos.extend(video_batches)\n","            labels.extend([label] * len(video_batches))\n","    return videos, labels\n","\n","def inferenceV3_BiLSTM():\n","    model_path = 'converted_model_ConvLSTM_Quantizzazione_Int.tflite'\n","    violence_path = '/content/gdrive/MyDrive/VideoInferenza/Violence'\n","    nonviolence_path = '/content/gdrive/MyDrive/VideoInferenza/NonViolence'\n","    input_shape = (224, 224)\n","    batch_size = 16\n","\n","    interpreter = load_tflite_model(model_path)\n","\n","    violence_videos, violence_labels = load_videos_from_folder(violence_path, 1, input_shape, batch_size)\n","    nonviolence_videos, nonviolence_labels = load_videos_from_folder(nonviolence_path, 0, input_shape, batch_size)\n","\n","    all_videos = violence_videos + nonviolence_videos\n","    all_labels = violence_labels + nonviolence_labels\n","\n","    all_videos = np.array([np.expand_dims(video, axis=0) for video in all_videos])\n","    all_labels = np.array(all_labels)\n","\n","    total_inference_time = 0\n","    y_probs = []\n","    for video in all_videos:\n","        output_data, inference_time = run_inference(interpreter, video)\n","        total_inference_time += inference_time\n","        y_probs.append(output_data.ravel()[0] / 255.0)\n","\n","    y_probs = np.array(y_probs)\n","    print(f\"Probabilità {y_probs}\")\n","    y_pred = np.round(y_probs)\n","\n","\n","\n","    print(\"Unique values in all_labels:\", np.unique(all_labels))\n","    print(\"Unique values in y_pred:\", np.unique(y_pred))\n","\n","\n","    accuracy, precision, recall, specificity, roc_auc, fpr, tpr = calculate_metrics(all_labels, y_pred, y_probs)\n","\n","\n","    average_inference_time = total_inference_time / len(all_videos)\n","\n","\n","    print(f'Accuracy: {accuracy:.4f}')\n","    print(f'Precision: {precision:.4f}')\n","    print(f'Recall: {recall:.4f}')\n","    print(f'Specificity: {specificity:.4f}')\n","    print(f'ROC AUC: {roc_auc:.4f}')\n","    print(f'Average Inference Time: {average_inference_time:.4f} seconds')\n","\n","\n","    print('Classification Report:')\n","    print(classification_report(all_labels, y_pred))\n","\n","    print('Confusion Matrix:')\n","    print(confusion_matrix(all_labels, y_pred))\n","\n","\n","    plot_roc_curve(fpr, tpr, roc_auc, title='ROC Curve for tf_model_mv3_convLStm')\n","\n","if __name__ == '__main__':\n","    inferenceV3_BiLSTM()\n"],"metadata":{"id":"I66q4DTlT_M8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Test sui tempi di inferenza per l'ultimo split sul modello BiLSTM**\n","\n","\n","*   **8 Cluster e centroidi a densità**: Accuratezza = 80%, AUC = 81.3%, tempo medio inferenza a batch = 0.47 s, peso: 558.4 MB, consumo energetico per 102 secondi di video: 0.0045 KW/h\n","\n","\n","*   **8 Cluster e centroidi lineari**: Accuratezza = 50.8 %, AUC = 77 %, tempo medio inferenza a batch = 0.489 s, peso: 558.4 MB, consumo energetico per 102 secondi di video: 0.004114 KW/h\n","\n","*   **8 Cluster e centroidi Kmeans++**: Accuratezza = 50.8 %, AUC =76.87  %, tempo medio inferenza a batch = 0.483 s, peso: 558 MB, consumo energetico per 102 secondi di video: 0.003682 KW/h\n","\n","*   **8 Cluster e centroidi Randomici**: Accuratezza = 32 %, AUC = 26 %, tempo medio inferenza a batch = 0.546 s, peso: 558 MB, consumo energetico per 102 secondi di video: 0.004158  KW/h\n","\n","*   **16 Cluster e centroide a densità**: Accuratezza = 53 %, AUC = 81.7 %, tempo medio inferenza a batch = 0.7550 s, peso: 558 MB, consumo energetico per 102 secondi di video: 0.005625 kWh KW/h\n","\n"],"metadata":{"id":"zlW5QVV7xhrg"}},{"cell_type":"code","source":["\n","from tensorflow.keras.models import load_model\n","\n","MobileNetV3Small_BiLSTM= load_model('/content/gdrive/MyDrive/Modelli/MobileNet_V3_Small/BiLSTM/final_model_fold_5.h5')\n","\n","\n","MobileNetV3Small_BiLSTM.summary()"],"metadata":{"id":"ggOavRawx1-q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","\n","\n","\n","for layer in MobileNetV3Small_BiLSTM.layers:\n","    weights = layer.get_weights()\n","    if weights:\n","        plt.figure(figsize=(8, 6))\n","        for i, w in enumerate(weights):\n","            plt.hist(w.flatten(), bins=50, alpha=0.7, color='blue')\n","\n","        if 'time_distributed' in layer.name:\n","            plt.xlim(-100, 100)\n","\n","        plt.title(f'Disribuzione dei pesi per {layer.name}')\n","        plt.xlabel('Valore dei pesi')\n","        plt.ylabel('Frequenza')\n","        plt.grid(True)\n","        plt.tight_layout()\n","        plt.show()\n","\n"],"metadata":{"id":"TQf2Rm_1x7mO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import numpy as np\n","\n","\n","layer_names = []\n","weight_counts = []\n","mean_weights = []\n","\n","\n","time_distributed_count = 0\n","bidirectional_count = 0\n","\n","\n","for layer in MobileNetV3Small_BiLSTM.layers:\n","    weights = layer.get_weights()\n","    if weights:\n","        total_weights = sum(w.size for w in weights)\n","        mean_weight = sum(w.mean() for w in weights) / len(weights)\n","        layer_names.append(layer.name)\n","        weight_counts.append(total_weights)\n","        mean_weights.append(mean_weight)\n","\n","\n","        if isinstance(layer, tf.keras.layers.TimeDistributed):\n","            time_distributed_count += total_weights\n","        elif isinstance(layer, tf.keras.layers.Bidirectional):\n","            bidirectional_count += total_weights\n","\n","\n","print(f'Totale pesi nel layer TimeDistributed: {time_distributed_count}')\n","print(f'Totale pesi nel layer Bidirectional: {bidirectional_count}')\n","\n","\n","fig, ax = plt.subplots(figsize=(10, 8))\n","wedges, texts, autotexts = ax.pie(weight_counts, labels=layer_names, autopct='%1.1f%%', textprops={'weight': 'bold'})\n","\n","\n","plt.tight_layout()\n","\n","\n","legend_labels = [f'{layer_names[i]}: {mean_weights[i]:.2f}' for i in range(len(layer_names))]\n","ax.legend(wedges, legend_labels, title='Layer e Media Pesi', loc='upper right', bbox_to_anchor=(1, 1))\n","\n","plt.title('Distribuzione dei pesi per ciascun layer')\n","plt.show()\n"],"metadata":{"id":"_63FIMvoQI_5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","import tensorflow as tf\n","\n","\n","for layer in MobileNetV3Small_BiLSTM.layers:\n","    weights = layer.get_weights()\n","    if weights:\n","        print(f\"Layer: {layer.name}\")\n","        for i, weight in enumerate(weights):\n","            print(f\"  Weight {i}: shape={weight.shape}, dtype={weight.dtype}\")\n"],"metadata":{"id":"VNPvtCVbyIpM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install tensorflow-model-optimization"],"metadata":{"id":"mPwSeHk3yPxb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","import tensorflow as tf\n","import tensorflow_model_optimization as tfmot\n","from tensorflow import keras\n","\n","cluster_weights = tfmot.clustering.keras.cluster_weights\n","CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n","\n","NUM_CLUSTER = 16\n","clustering_params = {\n","  'number_of_clusters': NUM_CLUSTER,\n","  'cluster_centroids_init': CentroidInitialization.DENSITY_BASED\n","}\n","\n","\n","def custom_cluster_weights(layer):\n","    if isinstance(layer, keras.layers.ConvLSTM2D):\n","        return layer\n","    else:\n","        return cluster_weights(layer, **clustering_params)\n","\n","\n","clustered_model = keras.models.clone_model(\n","    MobileNetV3Small_BiLSTM,\n","    clone_function=custom_cluster_weights\n",")\n","\n","opt = keras.optimizers.Adam(learning_rate=1e-5)\n","\n","clustered_model.compile(\n","  loss=keras.losses.BinaryCrossentropy(),\n","  optimizer=opt,\n","  metrics=['accuracy'])\n","\n","clustered_model.save(\"/content/gdrive/My Drive/Modelli/MobileNet_V3_Small/Clusterizzazione/BiLSTM/clustered_model_BiLSTM_8Density.h5\")\n","\n","clustered_model.summary()\n"],"metadata":{"id":"cidNPWIRyV-k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","import os\n","import numpy as np\n","import cv2\n","import tensorflow as tf\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, accuracy_score, precision_score, recall_score\n","import matplotlib.pyplot as plt\n","import time\n","\n","\n","def preprocess_video(video_path, input_shape, batch_size):\n","    cap = cv2.VideoCapture(video_path)\n","    frames = []\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        frame = cv2.resize(frame, (input_shape[1], input_shape[0]))\n","        frame = frame.astype('float32')\n","        frames.append(frame)\n","\n","    cap.release()\n","    frames = np.array(frames)\n","\n","\n","    if len(frames) >= batch_size:\n","        num_batches = len(frames) // batch_size\n","        frames = frames[:num_batches * batch_size]\n","        batches = np.split(frames, num_batches)\n","    else:\n","        batches = []\n","\n","    return batches\n","\n","\n","def load_videos_from_folder(folder_path, label, input_shape, batch_size):\n","    videos = []\n","    labels = []\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith(\".mp4\") or filename.endswith(\".avi\"):\n","            video_path = os.path.join(folder_path, filename)\n","            video_batches = preprocess_video(video_path, input_shape, batch_size)\n","            videos.extend(video_batches)\n","            labels.extend([label] * len(video_batches))\n","    return videos, labels\n","\n","\n","def fine_tune_model_with_videos(model, train_folder_violence, train_folder_nonviolence, input_shape, batch_size, epochs, validation_split=0.1):\n","    violence_videos, violence_labels = load_videos_from_folder(train_folder_violence, 1, input_shape, batch_size)\n","    nonviolence_videos, nonviolence_labels = load_videos_from_folder(train_folder_nonviolence, 0, input_shape, batch_size)\n","\n","\n","    print(f'Number of violence video batches: {len(violence_videos)}')\n","    print(f'Number of non-violence video batches: {len(nonviolence_videos)}')\n","\n","    all_videos = np.concatenate((violence_videos, nonviolence_videos), axis=0)\n","    all_labels = np.concatenate((violence_labels, nonviolence_labels), axis=0)\n","\n","    print(f'Number of total video batches: {len(all_videos)}')\n","    print(f'Number of total labels: {len(all_labels)}')\n","\n","    model.fit(\n","        all_videos,\n","        all_labels,\n","        batch_size=batch_size,\n","        epochs=epochs,\n","        validation_split=validation_split\n","    )\n","\n","    return model, all_videos, all_labels\n","\n","model_path = '/content/gdrive/My Drive/Modelli/MobileNet_V3_Small/Clusterizzazione/BiLSTM/clustered_model_BiLSTM_8Density.h5'\n","train_folder_violence = '/content/gdrive/MyDrive/Dataset/Data_Augmented/Violence'\n","train_folder_nonviolence = '/content/gdrive/MyDrive/Dataset/Data_Augmented/NonViolence'\n","input_shape = (224, 224)\n","sequence_length = 16\n","batch_size = 16\n","epochs = 1\n","\n","\n","model, all_videos, all_labels = fine_tune_model_with_videos(clustered_model, train_folder_violence, train_folder_nonviolence, input_shape, batch_size, epochs)\n","\n","model.save('/content/gdrive/My Drive/Modelli/MobileNet_V3_Small/Clusterizzazione/BiLSTM/clustered_tuned_model_BiLSTM_8Density.h5')\n"],"metadata":{"id":"joBSJn5fznSn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_quantized_size = os.path.getsize('/content/gdrive/My Drive/Modelli/MobileNet_V3_Small/Clusterizzazione/BiLSTM/clustered_tuned_model_BiLSTM_8Density.h5')\n","model_quantized_size_mb = model_quantized_size / (1024 * 1024)\n","print(f\"/content/gdrive/My Drive/Modelli/MobileNet_V3_Small/Clusterizzazione/BiLSTM/clustered_tuned_model_BiLSTM_8Density.h5'  Peso modello: {model_quantized_size_mb} MB\")"],"metadata":{"id":"fVZx1Cwozz73"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","for layer in model.layers:\n","    weights = layer.get_weights()\n","    if weights:\n","        plt.figure(figsize=(8, 6))\n","        for i, w in enumerate(weights):\n","            plt.hist(w.flatten(), bins=50, alpha=0.7, color='blue')\n","\n","        if 'time_distributed' in layer.name:\n","            plt.xlim(-100, 100)\n","\n","        plt.title(f'Disribuzione dei pesi per {layer.name} , cluster settati: {NUM_CLUSTER}')\n","        plt.xlabel('Valore dei pesi')\n","        plt.ylabel('Frequenza')\n","        plt.grid(True)\n","        plt.tight_layout()\n","        plt.show()\n"],"metadata":{"id":"Wv5Cs2VeycDw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","import os\n","import numpy as np\n","import cv2\n","import tensorflow as tf\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, accuracy_score, precision_score, recall_score\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import load_model\n","import time\n","\n","def load_keras_model(model_path):\n","    model = load_model(model_path)\n","    return model\n","\n","def preprocess_video(video_path, input_shape, batch_size):\n","    cap = cv2.VideoCapture(video_path)\n","    frames = []\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        frame = cv2.resize(frame, (input_shape[1], input_shape[0]))\n","        frame = frame.astype('float32')\n","        frames.append(frame)\n","\n","    cap.release()\n","    frames = np.array(frames)\n","\n","\n","    if len(frames) >= batch_size:\n","        num_batches = len(frames) // batch_size\n","        frames = frames[:num_batches * batch_size]\n","        batches = np.split(frames, num_batches)\n","    else:\n","\n","        batches = []\n","\n","    return batches\n","\n","def run_inference(model, input_data):\n","    output_data = model.predict(input_data)\n","    return output_data\n","\n","def calculate_metrics(y_true, y_pred, y_probs):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    specificity = recall_score(y_true, y_pred, pos_label=0)\n","    fpr, tpr, thresholds = roc_curve(y_true, y_probs)\n","    roc_auc = auc(fpr, tpr)\n","\n","    return accuracy, precision, recall, specificity, roc_auc, fpr, tpr\n","\n","def plot_roc_curve(fpr, tpr, roc_auc, title='ROC Curve'):\n","    plt.figure()\n","    plt.plot(fpr, tpr, color='b', lw=2, label='ROC curve (area = %0.4f)' % roc_auc)\n","    plt.plot([0, 1], [0, 1], color='r', linestyle='--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title(title)\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","def load_videos_from_folder(folder_path, label, input_shape, batch_size):\n","    videos = []\n","    labels = []\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith(\".mp4\") or filename.endswith(\".avi\"):\n","            video_path = os.path.join(folder_path, filename)\n","            video_batches = preprocess_video(video_path, input_shape, batch_size)\n","            videos.extend(video_batches)\n","            labels.extend([label] * len(video_batches))\n","    return videos, labels\n","\n","from codecarbon import track_emissions\n","@track_emissions(project_name=\"MV3_Small_Inference_ConvLSTM_quantizzato_Float_pruned\")\n","def inferenceV3_BiLSTM_Clusterizzata():\n","    violence_path = '/content/gdrive/MyDrive/VideoInferenza/Violence'\n","    nonviolence_path = '/content/gdrive/MyDrive/VideoInferenza/NonViolence'\n","    input_shape = (224, 224)\n","    batch_size = 16\n","\n","\n","    violence_videos, violence_labels = load_videos_from_folder(violence_path, 1, input_shape, batch_size)\n","    nonviolence_videos, nonviolence_labels = load_videos_from_folder(nonviolence_path, 0, input_shape, batch_size)\n","\n","    all_videos = violence_videos + nonviolence_videos\n","    all_labels = violence_labels + nonviolence_labels\n","\n","    all_videos = np.array([np.expand_dims(video, axis=0) for video in all_videos])\n","    all_labels = np.array(all_labels)\n","\n","    total_inference_time = 0\n","    y_probs = []\n","    for video in all_videos:\n","        start_time = time.time()\n","        output_data = run_inference(model, video)\n","        end_time = time.time()\n","        inference_time = end_time - start_time\n","        total_inference_time += inference_time\n","        y_probs.append(output_data.ravel()[0])\n","\n","    y_probs = np.array(y_probs)\n","    y_pred = np.round(y_probs)\n","\n","\n","    accuracy, precision, recall, specificity, roc_auc, fpr, tpr = calculate_metrics(all_labels, y_pred, y_probs)\n","\n","\n","    average_inference_time_per_batch = total_inference_time / len(all_videos)\n","\n","\n","    print(f'Accuracy: {accuracy:.4f}')\n","    print(f'Precision: {precision:.4f}')\n","    print(f'Recall: {recall:.4f}')\n","    print(f'Specificity: {specificity:.4f}')\n","    print(f'ROC AUC: {roc_auc:.4f}')\n","    print(f'Average Inference Time per Batch: {average_inference_time_per_batch:.4f} seconds')\n","\n","\n","    print('Classification Report:')\n","    print(classification_report(all_labels, y_pred, target_names=['NonViolent', 'Violent']))\n","\n","    print('Confusion Matrix:')\n","    print(confusion_matrix(all_labels, y_pred))\n","\n","\n","    plot_roc_curve(fpr, tpr, roc_auc, title='ROC Curve for tf_model_mv3_BiLStm')\n","\n","if __name__ == '__main__':\n","    inferenceV3_BiLSTM_Clusterizzata()\n"],"metadata":{"id":"DSeYszlEyjkI"},"execution_count":null,"outputs":[]}]}