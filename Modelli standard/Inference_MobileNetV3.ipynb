{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1OBbpjZKUh4Xd2F6LBMLbodEGeVwsmRI6","authorship_tag":"ABX9TyNUYf+inaqFKAQZ0vKD1mPd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"x9cduLOoSNQ5"},"outputs":[],"source":["\n","import pandas as pd\n","import numpy as np\n","import sklearn\n","from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n","from sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix, classification_report\n","from keras.callbacks import EarlyStopping\n","import matplotlib.pylab as plt\n","import os\n","from keras.models import Sequential, Model\n","from keras.layers import Input, Dense, Dropout, Flatten, ConvLSTM2D, TimeDistributed, Bidirectional, LSTM\n","#from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input as vgg16_preprocess_input\n","#from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input as mobilenet_v2_preprocess_input\n","from keras.utils import Sequence\n","from tensorflow.keras.callbacks import Callback\n","\n","\n","class DataGen(Sequence):\n","    \"\"\" A sequence of data for training/test/validation, loaded from memory\n","    batch by batch. Extends the tensorflow.keras.utils.Sequence: https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence\n","\n","    Attributes\n","    ----------\n","    base_path : str\n","                path to the folder including the samples.\n","    filenames : list<str>\n","                list of sample filenames.\n","    labels : list<str>\n","             list of sample labels.\n","    batch_size : int\n","                 batch size to load samples\n","\n","    \"\"\"\n","\n","    def __init__(self, base_path, filenames, labels, batch_size, Preprocess_input):\n","        self.base_path = base_path\n","        self.filenames = filenames\n","        self.labels = labels\n","        self.batch_size = batch_size\n","        self.Preprocess_input = Preprocess_input\n","\n","    def __len__(self):\n","        return (np.ceil(len(self.filenames) / float(self.batch_size))).astype(int)\n","\n","    def __getitem__(self, idx):\n","        batch_x = self.filenames[idx * self.batch_size: (idx + 1) * self.batch_size]\n","        batch_y = self.labels[idx * self.batch_size: (idx + 1) * self.batch_size]\n","\n","        return np.array([self.Preprocess_input(np.load(os.path.join(self.base_path, file_name))) for file_name in batch_x]), np.array(batch_y)\n","\n","def GetPretrainedModel(ModelConstructor, input_shape=(224, 224, 3), print_summary=True):\n","    \"\"\" Builds the VGG16 2D CNN with the Imagenet weights, freezing all layers except layers_to_finetune\n","\n","    Parameters\n","    ----------\n","    ModelConstructor : Callable[[bool], [str], [tuple], Sequential]\n","                       Function that download the pretrained model, i.e. one of the Keras applications:\n","                       https://keras.io/api/applications/\n","                       The arguments are include_top, weights, and input_shape.\n","    input_shape : tuple\n","                  The input shape for the pretrained model.\n","    print_summary : bool\n","                    If True prints the model summary.\n","\n","    Returns\n","    -------\n","    model : Sequential\n","          The instantiated model.\n","    \"\"\"\n","\n","    model = ModelConstructor(include_top=False, weights=\"imagenet\", input_shape=input_shape)\n","\n","    for layer in model.layers:\n","        layer.trainable = False\n","\n","    return model\n","\n","def getLSTMModel(getConvModel, ModelConstructor, pretrained_input_shape=(224, 224, 3), verbose=True):\n","    \"\"\"Creates the BiLSTM + fully connected layers end-to-end model object\n","    with the sequential API: https://keras.io/models/sequential/\n","\n","    Parameters\n","    ----------\n","    getConvModel : Callable[Callable[[bool], [str], [tuple], Sequential], [tuple], [bool], Sequential]\n","                Function that instantiates the pretrained Convolutional model\n","                to be applied in a time distributed fashion.\n","    ModelConstructor : Callable[[bool], [str], [tuple], Sequential]\n","                       Function that download the pretrained model, i.e. one of the Keras applications:\n","                       https://keras.io/api/applications/\n","                       The arguments are include_top, weights, and input_shape.\n","    input_shape : tuple\n","                  The input shape for the pretrained model.\n","    verbose : bool\n","              if True prints the model summary (default True)\n","\n","    Returns\n","    -------\n","    model : Sequential\n","            The instantiated model\n","    \"\"\"\n","    model = Sequential()\n","    model.add(TimeDistributed(getConvModel(ModelConstructor, pretrained_input_shape, verbose), input_shape=(16, 224, 224, 3)))\n","\n","    model.add(TimeDistributed(Flatten()))\n","    model.add(Bidirectional(LSTM(units=128, return_sequences=False)))\n","    #model.add(LSTM(units=128, return_sequences=False))\n","\n","    model.add(Dropout(0.5))\n","    model.add(Dense(128, activation='relu'))\n","\n","    model.add(Dropout(0.5))\n","    model.add(Dense(1, activation='sigmoid'))\n","    if verbose:\n","        model.summary()\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","    return model\n","\n","def getConvLSTMModel(getConvModel, ModelConstructor, pretrained_input_shape=(224, 224, 3), verbose=True):\n","    \"\"\"Creates the BiLSTM + fully connected layers end-to-end model object\n","    with the sequential API: https://keras.io/models/sequential/\n","\n","    Parameters\n","    ----------\n","    getConvModel : Callable[Callable[[bool], [str], [tuple], Sequential], [tuple], [bool], Sequential]\n","                Function that instantiates the pretrained Convolutional model\n","                to be applied in a time distributed fashion.\n","    ModelConstructor : Callable[[bool], [str], [tuple], Sequential]\n","                       Function that download the pretrained model, i.e. one of the Keras applications:\n","                       https://keras.io/api/applications/\n","                       The arguments are include_top, weights, and input_shape.\n","    input_shape : tuple\n","                  The input shape for the pretrained model.\n","    verbose : bool\n","              if True prints the model summary (default True)\n","\n","    Returns\n","    -------\n","    model : Sequential\n","            The instantiated model\n","    \"\"\"\n","    model = Sequential()\n","    model.add(TimeDistributed(getConvModel(ModelConstructor, pretrained_input_shape, verbose), input_shape=(16, 224, 224, 3)))\n","\n","    model.add(ConvLSTM2D(filters=64, kernel_size=(3, 3)))\n","\n","    model.add(Flatten())\n","    model.add(Dropout(0.5))\n","    model.add(Dense(256, activation='relu'))\n","\n","    model.add(Dropout(0.5))\n","    model.add(Dense(1, activation='sigmoid'))\n","    if verbose:\n","        model.summary()\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","    return model\n","\n","# definitions of two end-to-end models + definitions of experiments\n","import pandas as pd\n","import numpy as np\n","import sklearn\n","from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n","from sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix, classification_report\n","from keras.callbacks import EarlyStopping\n","import matplotlib.pylab as plt\n","import os\n","from keras.models import Sequential, Model\n","from keras.layers import Input, Dense, Dropout, Flatten, ConvLSTM2D, TimeDistributed, Bidirectional, LSTM\n","#from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input as vgg16_preprocess_input\n","#from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input as mobilenet_v2_preprocess_input\n","from keras.utils import Sequence\n","\n","class DataGen(Sequence):\n","    \"\"\" A sequence of data for training/test/validation, loaded from memory\n","    batch by batch. Extends the tensorflow.keras.utils.Sequence: https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence\n","\n","    Attributes\n","    ----------\n","    base_path : str\n","                path to the folder including the samples.\n","    filenames : list<str>\n","                list of sample filenames.\n","    labels : list<str>\n","             list of sample labels.\n","    batch_size : int\n","                 batch size to load samples\n","\n","    \"\"\"\n","\n","    def __init__(self, base_path, filenames, labels, batch_size, Preprocess_input):\n","        self.base_path = base_path\n","        self.filenames = filenames\n","        self.labels = labels\n","        self.batch_size = batch_size\n","        self.Preprocess_input = Preprocess_input\n","\n","    def __len__(self):\n","        return (np.ceil(len(self.filenames) / float(self.batch_size))).astype(int)\n","\n","    def __getitem__(self, idx):\n","        batch_x = self.filenames[idx * self.batch_size: (idx + 1) * self.batch_size]\n","        batch_y = self.labels[idx * self.batch_size: (idx + 1) * self.batch_size]\n","\n","        return np.array([self.Preprocess_input(np.load(os.path.join(self.base_path, file_name))) for file_name in batch_x]), np.array(batch_y)\n","\n","def GetPretrainedModel(ModelConstructor, input_shape=(224, 224, 3), print_summary=True):\n","    \"\"\" Builds the VGG16 2D CNN with the Imagenet weights, freezing all layers except layers_to_finetune\n","\n","    Parameters\n","    ----------\n","    ModelConstructor : Callable[[bool], [str], [tuple], Sequential]\n","                       Function that download the pretrained model, i.e. one of the Keras applications:\n","                       https://keras.io/api/applications/\n","                       The arguments are include_top, weights, and input_shape.\n","    input_shape : tuple\n","                  The input shape for the pretrained model.\n","    print_summary : bool\n","                    If True prints the model summary.\n","\n","    Returns\n","    -------\n","    model : Sequential\n","          The instantiated model.\n","    \"\"\"\n","\n","    model = ModelConstructor(include_top=False, weights=\"imagenet\", input_shape=input_shape)\n","\n","    for layer in model.layers:\n","        layer.trainable = False\n","\n","    return model\n","\n","def getLSTMModel(getConvModel, ModelConstructor, pretrained_input_shape=(224, 224, 3), verbose=True):\n","    \"\"\"Creates the BiLSTM + fully connected layers end-to-end model object\n","    with the sequential API: https://keras.io/models/sequential/\n","\n","    Parameters\n","    ----------\n","    getConvModel : Callable[Callable[[bool], [str], [tuple], Sequential], [tuple], [bool], Sequential]\n","                Function that instantiates the pretrained Convolutional model\n","                to be applied in a time distributed fashion.\n","    ModelConstructor : Callable[[bool], [str], [tuple], Sequential]\n","                       Function that download the pretrained model, i.e. one of the Keras applications:\n","                       https://keras.io/api/applications/\n","                       The arguments are include_top, weights, and input_shape.\n","    input_shape : tuple\n","                  The input shape for the pretrained model.\n","    verbose : bool\n","              if True prints the model summary (default True)\n","\n","    Returns\n","    -------\n","    model : Sequential\n","            The instantiated model\n","    \"\"\"\n","    model = Sequential()\n","    model.add(TimeDistributed(getConvModel(ModelConstructor, pretrained_input_shape, verbose), input_shape=(16, 224, 224, 3)))\n","\n","    model.add(TimeDistributed(Flatten()))\n","    model.add(Bidirectional(LSTM(units=128, return_sequences=False)))\n","    #model.add(LSTM(units=128, return_sequences=False))\n","\n","    model.add(Dropout(0.5))\n","    model.add(Dense(128, activation='relu'))\n","\n","    model.add(Dropout(0.5))\n","    model.add(Dense(1, activation='sigmoid'))\n","    if verbose:\n","        model.summary()\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","    return model\n","\n","def getConvLSTMModel(getConvModel, ModelConstructor, pretrained_input_shape=(224, 224, 3), verbose=True):\n","    \"\"\"Creates the BiLSTM + fully connected layers end-to-end model object\n","    with the sequential API: https://keras.io/models/sequential/\n","\n","    Parameters\n","    ----------\n","    getConvModel : Callable[Callable[[bool], [str], [tuple], Sequential], [tuple], [bool], Sequential]\n","                Function that instantiates the pretrained Convolutional model\n","                to be applied in a time distributed fashion.\n","    ModelConstructor : Callable[[bool], [str], [tuple], Sequential]\n","                       Function that download the pretrained model, i.e. one of the Keras applications:\n","                       https://keras.io/api/applications/\n","                       The arguments are include_top, weights, and input_shape.\n","    input_shape : tuple\n","                  The input shape for the pretrained model.\n","    verbose : bool\n","              if True prints the model summary (default True)\n","\n","    Returns\n","    -------\n","    model : Sequential\n","            The instantiated model\n","    \"\"\"\n","    model = Sequential()\n","    model.add(TimeDistributed(getConvModel(ModelConstructor, pretrained_input_shape, verbose), input_shape=(16, 224, 224, 3)))\n","\n","    model.add(ConvLSTM2D(filters=64, kernel_size=(3, 3)))\n","\n","    model.add(Flatten())\n","    model.add(Dropout(0.5))\n","    model.add(Dense(256, activation='relu'))\n","\n","    model.add(Dropout(0.5))\n","    model.add(Dense(1, activation='sigmoid'))\n","    if verbose:\n","        model.summary()\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","    return model\n","\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix\n","from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n","\n","def runEndToEndExperiment(getLSTMModel, getConvModel, ModelConstructor, pretrained_input_shape, Preprocess_input, batchSize, datasetBasePath, npyBasePath, featuresPath, samplesMMapName, lablesMMapName, endToEndModelName, rState, savePath):\n","        return  getLSTMModel(getConvModel, ModelConstructor, pretrained_input_shape)\n","\n","\n","\n","\n","class InferenceTimeCallback(Callback):\n","    def on_predict_batch_begin(self, batch, logs=None):\n","        self.start_time = time.time()\n","\n","    def on_predict_batch_end(self, batch, logs=None):\n","        self.end_time = time.time()\n","        self.inference_time = self.end_time - self.start_time\n","        print(f\"Inference time for batch {batch}: {self.inference_time} seconds\")\n","\n","\n"]},{"cell_type":"code","source":["!pip install codecarbon"],"metadata":{"id":"lMsa4zPiahin"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Test sui tempi di inferenza per l'ultimo split sul modello ConvLSTM**\n","\n","\n","\n","*   Accuratezza: 95 %\n","*   Curva AUC: 99.4 %\n","*   Peso modello: 25.5 MB\n","*   Impronta di carbonio:   Kg/C02\n","*   Consumo Energetico medio per 102 secondi di video:  0.0018 kW/h\n","*   Tempo medio di inferenza per batch:  0.43  s\n","\n"],"metadata":{"id":"3Xnx6cHSSa1E"}},{"cell_type":"code","source":["# Monto il drive Google\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"metadata":{"id":"1Ivj_nB8SlRh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","from tensorflow.keras.applications import MobileNetV3Small\n","from tensorflow.keras.applications.mobilenet_v3 import preprocess_input as mobilenet_v3_preprocess_input\n","from tensorflow.keras.preprocessing import image\n","import matplotlib.pyplot as plt\n","\n","\n","MobileNetV3Small_ConvLSTM = runEndToEndExperiment(\n","    getConvLSTMModel,\n","    GetPretrainedModel,\n","    MobileNetV3Small,\n","    (224, 224, 3),\n","    mobilenet_v3_preprocess_input,\n","    8,\n","    '/content/gdrive/My Drive/Dataset/AirtLab-Dataset',\n","    '/airtlabDataset',\n","    'features',\n","    'filenames.npy',\n","    'labels.npy',\n","    'MobileNetV3Small + ConvLSTM',\n","    42,\n","    '/content/gdrive/ My Drive/MobileNetV3Small_ConvLSTM'\n",")\n","\n","\n","MobileNetV3Small_ConvLSTM.load_weights('/content/gdrive/MyDrive/Modelli/MobileNet_V3_Small/ConvLSTM/final_model_fold_5.h5')\n","\n"],"metadata":{"id":"pkaGvajDSzLr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import cv2\n","import tensorflow as tf\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, accuracy_score, precision_score, recall_score\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import load_model\n","import time\n","\n","\n","from codecarbon import track_emissions\n","\n","\n","def load_keras_model(model_path):\n","    model = load_model(model_path)\n","    return model\n","\n","def preprocess_video(video_path, input_shape, batch_size):\n","    cap = cv2.VideoCapture(video_path)\n","    frames = []\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        frame = cv2.resize(frame, (input_shape[1], input_shape[0]))\n","        frame = frame.astype('float32')  # / 255.0\n","        frames.append(frame)\n","\n","    cap.release()\n","    frames = np.array(frames)\n","\n","\n","    if len(frames) >= batch_size:\n","        num_batches = len(frames) // batch_size\n","        frames = frames[:num_batches * batch_size]\n","        batches = np.split(frames, num_batches)\n","    else:\n","\n","        batches = []\n","\n","    return batches\n","\n","\n","def run_inference(model, input_data):\n","    output_data = model.predict(input_data)\n","    return output_data\n","\n","def calculate_metrics(y_true, y_pred, y_probs):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    specificity = recall_score(y_true, y_pred, pos_label=0)\n","    fpr, tpr, thresholds = roc_curve(y_true, y_probs)\n","    roc_auc = auc(fpr, tpr)\n","\n","    return accuracy, precision, recall, specificity, roc_auc, fpr, tpr\n","\n","def plot_roc_curve(fpr, tpr, roc_auc, title='ROC Curve'):\n","    plt.figure()\n","    plt.plot(fpr, tpr, color='b', lw=2, label='ROC curve (area = %0.4f)' % roc_auc)\n","    plt.plot([0, 1], [0, 1], color='r', linestyle='--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title(title)\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","def load_videos_from_folder(folder_path, label, input_shape, batch_size):\n","    videos = []\n","    labels = []\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith(\".mp4\") or filename.endswith(\".avi\"):\n","            video_path = os.path.join(folder_path, filename)\n","            video_batches = preprocess_video(video_path, input_shape, batch_size)\n","            videos.extend(video_batches)\n","            labels.extend([label] * len(video_batches))\n","    return videos, labels\n","\n","@track_emissions(project_name=\"MV3_Small_Inference_ConvLSTM\")\n","def inferenceV3_ConvLSTM():\n","    model_path = '/content/gdrive/MyDrive/Modelli/MobileNet_V3_Small/ConvLSTM/final_model_fold_5.h5'\n","    violence_path = '/content/gdrive/MyDrive/VideoInferenza/Violence'\n","    nonviolence_path = '/content/gdrive/MyDrive/VideoInferenza/NonViolence'\n","    input_shape = (224, 224)\n","    batch_size = 16\n","\n","    model = load_keras_model(model_path)\n","\n","    violence_videos, violence_labels = load_videos_from_folder(violence_path, 1, input_shape, batch_size)\n","    nonviolence_videos, nonviolence_labels = load_videos_from_folder(nonviolence_path, 0, input_shape, batch_size)\n","\n","    all_videos = violence_videos + nonviolence_videos\n","    all_labels = violence_labels + nonviolence_labels\n","\n","    all_videos = np.array([np.expand_dims(video, axis=0) for video in all_videos])\n","    all_labels = np.array(all_labels)\n","\n","    total_inference_time = 0\n","    total_emissions = 0\n","    total_energy_consumed = 0\n","    y_probs = []\n","    for video in all_videos:\n","        start_time = time.time()\n","        output_data = run_inference(model, video)\n","        end_time = time.time()\n","        inference_time = end_time - start_time\n","        total_inference_time += inference_time\n","        y_probs.append(output_data.ravel()[0])\n","\n","    y_probs = np.array(y_probs)\n","    y_pred = np.round(y_probs)\n","\n","\n","    accuracy, precision, recall, specificity, roc_auc, fpr, tpr = calculate_metrics(all_labels, y_pred, y_probs)\n","\n","\n","    average_inference_time_per_batch = total_inference_time / len(all_videos)\n","\n","\n","    average_emissions_per_video = total_emissions / len(all_videos)\n","\n","\n","    average_energy_per_batch = total_energy_consumed / len(all_videos)\n","\n","\n","    print(f'Accuracy: {accuracy:.4f}')\n","    print(f'Precision: {precision:.4f}')\n","    print(f'Recall: {recall:.4f}')\n","    print(f'Specificity: {specificity:.4f}')\n","    print(f'ROC AUC: {roc_auc:.4f}')\n","    print(f'Average Inference Time per Batch: {average_inference_time_per_batch:.6f} seconds')\n","\n","\n","\n","    print('Classification Report:')\n","    print(classification_report(all_labels, y_pred, target_names=['NonViolent', 'Violent']))\n","\n","    print('Confusion Matrix:')\n","    print(confusion_matrix(all_labels, y_pred))\n","\n","\n","    plot_roc_curve(fpr, tpr, roc_auc, title='ROC Curve for tf_model_mv3_convLStm')\n","\n","if __name__ == '__main__':\n","    inferenceV3_ConvLSTM()\n"],"metadata":{"id":"UmfKOEM2f99z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Test sui tempi di inferenza per l'ultimo split sul modello BiLSTM**\n","\n","\n","\n","*   Accuratezza: 90.6 %\n","*   Curva AUC:  97.84 %\n","*   Peso modello: 336.6 MB\n","*   Consumo Energetico medio per 102 secondi di video:   0.0022 kw/h\n","*   Tempo medio di inferenza per batch: 0.7   s"],"metadata":{"id":"yJbjmH2zuvKO"}},{"cell_type":"code","source":["\n","\n","from tensorflow.keras.applications import MobileNetV3Small\n","from tensorflow.keras.applications.mobilenet_v3 import preprocess_input as mobilenet_v3_preprocess_input\n","from tensorflow.keras.preprocessing import image\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.callbacks import Callback\n","\n","\n","MobileNetV3Small_BiLSTM = runEndToEndExperiment(\n","    getLSTMModel,\n","    GetPretrainedModel,\n","    MobileNetV3Small,\n","    (224, 224, 3),\n","    mobilenet_v3_preprocess_input,\n","    8,\n","    '/content/gdrive/My Drive/Dataset/AirtLab-Dataset',\n","    '/airtlabDataset',\n","    'features',\n","    'filenames.npy',\n","    'labels.npy',\n","    'MobileNetV3Small + BiLSTM',\n","    42,\n","    '/content/gdrive/ My Drive/MobileNetV3Small_BiLSTM'\n",")\n","\n","\n","MobileNetV3Small_BiLSTM.load_weights('/content/gdrive/MyDrive/Modelli/MobileNet_V3_Small/BiLSTM/final_model_fold_5.h5')\n","\n"],"metadata":{"id":"ZpA9mqmDu2ZD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import cv2\n","import tensorflow as tf\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, accuracy_score, precision_score, recall_score\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import load_model\n","import time\n","\n","\n","\n","def load_keras_model(model_path):\n","    model = load_model(model_path)\n","    return model\n","\n","def preprocess_video(video_path, input_shape, batch_size):\n","    cap = cv2.VideoCapture(video_path)\n","    frames = []\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        frame = cv2.resize(frame, (input_shape[1], input_shape[0]))\n","        frame = frame.astype('float32') #/ 255.0\n","        frames.append(frame)\n","\n","    cap.release()\n","    frames = np.array(frames)\n","\n","\n","    if len(frames) >= batch_size:\n","        num_batches = len(frames) // batch_size\n","        frames = frames[:num_batches * batch_size]\n","        batches = np.split(frames, num_batches)\n","    else:\n","\n","        batches = []\n","\n","    return batches\n","\n","def run_inference(model, input_data):\n","    output_data = model.predict(input_data)\n","    return output_data\n","\n","def calculate_metrics(y_true, y_pred, y_probs):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    specificity = recall_score(y_true, y_pred, pos_label=0)\n","    fpr, tpr, thresholds = roc_curve(y_true, y_probs)\n","    roc_auc = auc(fpr, tpr)\n","\n","    return accuracy, precision, recall, specificity, roc_auc, fpr, tpr\n","\n","def plot_roc_curve(fpr, tpr, roc_auc, title='ROC Curve'):\n","    plt.figure()\n","    plt.plot(fpr, tpr, color='b', lw=2, label='ROC curve (area = %0.4f)' % roc_auc)\n","    plt.plot([0, 1], [0, 1], color='r', linestyle='--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title(title)\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","def load_videos_from_folder(folder_path, label, input_shape, batch_size):\n","    videos = []\n","    labels = []\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith(\".mp4\") or filename.endswith(\".avi\"):\n","            video_path = os.path.join(folder_path, filename)\n","            video_batches = preprocess_video(video_path, input_shape, batch_size)\n","            videos.extend(video_batches)\n","            labels.extend([label] * len(video_batches))\n","    return videos, labels\n","\n","\n","from codecarbon import track_emissions\n","@track_emissions(project_name=\"MV3_Small_Inference_BiLSTM\")\n","def inferenceV3_BiLSTM():\n","    model_path = '/content/gdrive/MyDrive/Modelli/MobileNet_V3_Small/BiLSTM/final_model_fold_5.h5'\n","    violence_path = '/content/gdrive/MyDrive/VideoInferenza/Violence'\n","    nonviolence_path = '/content/gdrive/MyDrive/VideoInferenza/NonViolence'\n","    input_shape = (224, 224)\n","    batch_size = 16\n","\n","    model = load_keras_model(model_path)\n","\n","    violence_videos, violence_labels = load_videos_from_folder(violence_path, 1, input_shape, batch_size)\n","    nonviolence_videos, nonviolence_labels = load_videos_from_folder(nonviolence_path, 0, input_shape, batch_size)\n","\n","    all_videos = violence_videos + nonviolence_videos\n","    all_labels = violence_labels + nonviolence_labels\n","\n","    all_videos = np.array([np.expand_dims(video, axis=0) for video in all_videos])\n","    all_labels = np.array(all_labels)\n","\n","    total_inference_time = 0\n","    y_probs = []\n","    for video in all_videos:\n","        start_time = time.time()\n","        output_data = run_inference(model, video)\n","        end_time = time.time()\n","        inference_time = end_time - start_time\n","        total_inference_time += inference_time\n","        y_probs.append(output_data.ravel()[0])\n","\n","    y_probs = np.array(y_probs)\n","    y_pred = np.round(y_probs)\n","\n","\n","    accuracy, precision, recall, specificity, roc_auc, fpr, tpr = calculate_metrics(all_labels, y_pred, y_probs)\n","\n","\n","    average_inference_time_per_batch = total_inference_time / len(all_videos)\n","\n","\n","    print(f'Accuracy: {accuracy:.4f}')\n","    print(f'Precision: {precision:.4f}')\n","    print(f'Recall: {recall:.4f}')\n","    print(f'Specificity: {specificity:.4f}')\n","    print(f'ROC AUC: {roc_auc:.4f}')\n","    print(f'Average Inference Time per Batch: {average_inference_time_per_batch:.4f} seconds')\n","\n","\n","    print('Classification Report:')\n","    print(classification_report(all_labels, y_pred, target_names=['NonViolent', 'Violent']))\n","\n","    print('Confusion Matrix:')\n","    print(confusion_matrix(all_labels, y_pred))\n","\n","\n","    plot_roc_curve(fpr, tpr, roc_auc, title='ROC Curve for tf_model_mv3_BiLStm')\n","\n","if __name__ == '__main__':\n","    inferenceV3_BiLSTM()"],"metadata":{"id":"SwKJFv2YvGyi"},"execution_count":null,"outputs":[]}]}