{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["W1Mrl6xHhtX6","ejjht9o_iSb-"],"authorship_tag":"ABX9TyPNHyIvuacthzJ/D8Mqs0DW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Monto il drive Google\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"metadata":{"id":"YRvJBkyij-nS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install codecarbon"],"metadata":{"id":"vUzrNQ3lJdwH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Modello MobileNet-V3 Small + ConvLSTM (5° Split)\n","\n","\n","*   Peso modello: circa 12 MB\n","*   Accuratezza modello: 95 %\n","*   Auc: circa 99 %\n","*   Tempo inferenza medio per batch: 0.445 s\n","*   Consumo Energetico medio per 102 secondi di video:  0.001762  kW/h"],"metadata":{"id":"W1Mrl6xHhtX6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lXEFwaq8hmX8"},"outputs":[],"source":["# Informazioni sul peso del modello\n","\n","import os\n","\n","MODEL_PATH_CONV = \"/content/gdrive/MyDrive/Modelli/MobileNet_V3_Small/Quantizzazione Aware Training/ConvLSTm/final_model_fold_5.tflite\"\n","\n","\n","if os.path.exists(MODEL_PATH_CONV):\n","    file_size_bytes = os.path.getsize(MODEL_PATH_CONV)\n","    file_size_mb = file_size_bytes / (1024 * 1024)\n","    print(f\"Dimensione del file: {file_size_mb:.2f} MB\")\n","else:\n","    print(\"Il file specificato non esiste.\")"]},{"cell_type":"code","source":["# Funzioni di preprocessamento dei video e di inferenza\n","\n","import os\n","import numpy as np\n","import cv2\n","import tensorflow as tf\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, accuracy_score, precision_score, recall_score\n","import matplotlib.pyplot as plt\n","import time\n","\n","def load_tflite_model(model_path):\n","    interpreter = tf.lite.Interpreter(model_path=MODEL_PATH_CONV)\n","    interpreter.allocate_tensors()\n","    return interpreter\n","\n","def preprocess_video(video_path, input_shape, batch_size):\n","    cap = cv2.VideoCapture(video_path)\n","    frames = []\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        frame = cv2.resize(frame, (input_shape[1], input_shape[0]))\n","        frame = frame.astype('float32')\n","        frames.append(frame)\n","\n","    cap.release()\n","    frames = np.array(frames)\n","\n","    if len(frames) >= batch_size:\n","        num_batches = len(frames) // batch_size\n","        frames = frames[:num_batches * batch_size]\n","        batches = np.split(frames, num_batches)\n","    else:\n","        batches = []\n","\n","    return batches\n","\n","def run_inference(interpreter, input_data):\n","    input_details = interpreter.get_input_details()\n","    output_details = interpreter.get_output_details()\n","\n","    interpreter.set_tensor(input_details[0]['index'], input_data)\n","\n","    # Calcola il tempo di inferenza\n","    start_time = time.time()\n","    interpreter.invoke()\n","    end_time = time.time()\n","    inference_time = end_time - start_time\n","\n","    output_data = interpreter.get_tensor(output_details[0]['index'])\n","\n","    return output_data, inference_time\n","\n","def calculate_metrics(y_true, y_pred, y_probs):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    specificity = recall_score(y_true, y_pred, pos_label=0)\n","    fpr, tpr, thresholds = roc_curve(y_true, y_probs)\n","    roc_auc = auc(fpr, tpr)\n","\n","    return accuracy, precision, recall, specificity, roc_auc, fpr, tpr\n","\n","def plot_roc_curve(fpr, tpr, roc_auc, title='ROC Curve'):\n","    plt.figure()\n","    plt.plot(fpr, tpr, color='b', lw=2, label='ROC curve (area = %0.4f)' % roc_auc)\n","    plt.plot([0, 1], [0, 1], color='r', linestyle='--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title(title)\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","def load_videos_from_folder(folder_path, label, input_shape, batch_size):\n","    videos = []\n","    labels = []\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith(\".mp4\") or filename.endswith(\".avi\"):\n","            video_path = os.path.join(folder_path, filename)\n","            video_batches = preprocess_video(video_path, input_shape, batch_size)\n","            videos.extend(video_batches)\n","            labels.extend([label] * len(video_batches))\n","    return videos, labels\n","\n","\n","\n","from codecarbon import track_emissions\n","@track_emissions(project_name=\"MV3_Small_Inference_ConvLSTM_QAT\")\n","def inferenceV3_ConvLSTM():\n","    MODEL_PATH_CONV = '/content/gdrive/MyDrive/Modelli/MobileNet_V3_Small/Quantizzazione Aware Training/ConvLSTm/final_model_fold_5.tflite'\n","    violence_path = '/content/gdrive/MyDrive/VideoInferenza/Violence'\n","    nonviolence_path = '/content/gdrive/MyDrive/VideoInferenza/NonViolence'\n","    input_shape = (224, 224)\n","    batch_size = 16\n","\n","    interpreter = load_tflite_model(MODEL_PATH_CONV)\n","\n","    violence_videos, violence_labels = load_videos_from_folder(violence_path, 1, input_shape, batch_size)\n","    nonviolence_videos, nonviolence_labels = load_videos_from_folder(nonviolence_path, 0, input_shape, batch_size)\n","\n","    all_videos = violence_videos + nonviolence_videos\n","    all_labels = violence_labels + nonviolence_labels\n","\n","    all_videos = np.array([np.expand_dims(video, axis=0) for video in all_videos])\n","    all_labels = np.array(all_labels)\n","\n","    total_inference_time = 0\n","    y_probs = []\n","    for video in all_videos:\n","        output_data, inference_time = run_inference(interpreter, video)\n","        total_inference_time += inference_time\n","        y_probs.append(output_data.ravel()[0])\n","\n","    y_probs = np.array(y_probs)\n","    y_pred = np.round(y_probs)\n","\n","    # Calculate metrics\n","    accuracy, precision, recall, specificity, roc_auc, fpr, tpr = calculate_metrics(all_labels, y_pred, y_probs)\n","\n","    # Calculate average inference time\n","    average_inference_time = total_inference_time / len(all_videos)\n","\n","    # Print metrics\n","    print(f'Accuracy: {accuracy:.4f}')\n","    print(f'Precision: {precision:.4f}')\n","    print(f'Recall: {recall:.4f}')\n","    print(f'Specificity: {specificity:.4f}')\n","    print(f'ROC AUC: {roc_auc:.4f}')\n","    print(f'Average Inference Time: {average_inference_time:.4f} seconds')\n","\n","    # Print classification report and confusion matrix\n","    print('Classification Report:')\n","    print(classification_report(all_labels, y_pred))\n","\n","    print('Confusion Matrix:')\n","    print(confusion_matrix(all_labels, y_pred))\n","\n","    # Plot ROC curve\n","    plot_roc_curve(fpr, tpr, roc_auc, title='ROC Curve for tf_model_mv3_convLStm_QAt')\n","\n","if __name__ == '__main__':\n","    inferenceV3_ConvLSTM()\n"],"metadata":{"id":"jBPEzRbisui1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Modello MobileNet-V3 Small + BiLstm (5° Split)\n","\n","\n","*   Peso modello: circa 114.5 MB\n","*   Accuratezza modello: 81.77 %\n","*   Auc: circa 99.82 %\n","*   Tempo inferenza medio per batch: 0.38 s\n","*   Consumo Energetico medio per 102 secondi di video: 0.001538  kW/h"],"metadata":{"id":"ejjht9o_iSb-"}},{"cell_type":"code","source":["# Carico il modello, ho salvato i pesi .h5 dell'aware training quindi occorre fare un\n","# passaggio extra per riconvertirlo in tflite\n","\n","#import tensorflow_model_optimization as tfmot\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","import keras\n","\n","\n","def load_model_as_tflite(model):\n","    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","\n","    converter.target_spec.supported_ops = [\n","      tf.lite.OpsSet.TFLITE_BUILTINS,\n","      tf.lite.OpsSet.SELECT_TF_OPS\n","    ]\n","    # Disabilita le operazioni non supportate\n","    converter._experimental_lower_tensor_list_ops = False\n","\n","    tflite_model = converter.convert()\n","\n","    return tflite_model\n"],"metadata":{"id":"Gkd-g8PkjOtM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Informazioni sul peso del modello\n","\n","MODEL_PATH = \"/content/gdrive/MyDrive/Modelli/MobileNet_V3_Small/Quantizzazione Aware Training/BiLSTM/BiLSTM_tfLite_ultimo_split.tflite\"\n","\n","\n","if os.path.exists(MODEL_PATH):\n","    file_size_bytes = os.path.getsize(MODEL_PATH)\n","    file_size_mb = file_size_bytes / (1024 * 1024)\n","    print(f\"Dimensione del file: {file_size_mb:.2f} MB\")\n","else:\n","    print(\"Il file specificato non esiste.\")"],"metadata":{"id":"S0WU4iX8pFkH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Funzioni di preprocessamento e di inferenza\n","\n","import os\n","import numpy as np\n","import cv2\n","import tensorflow as tf\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, accuracy_score, precision_score, recall_score\n","import matplotlib.pyplot as plt\n","import time\n","\n","def load_tflite_model(model_path):\n","    interpreter = tf.lite.Interpreter(model_path=MODEL_PATH)\n","    interpreter.allocate_tensors()\n","    return interpreter\n","\n","def preprocess_video(video_path, input_shape, batch_size):\n","    cap = cv2.VideoCapture(video_path)\n","    frames = []\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        frame = cv2.resize(frame, (input_shape[1], input_shape[0]))\n","        frame = frame.astype('float32')\n","        frames.append(frame)\n","\n","    cap.release()\n","    frames = np.array(frames)\n","\n","    if len(frames) >= batch_size:\n","        num_batches = len(frames) // batch_size\n","        frames = frames[:num_batches * batch_size]\n","        batches = np.split(frames, num_batches)\n","    else:\n","        batches = []\n","\n","    return batches\n","\n","def run_inference(interpreter, input_data):\n","    input_details = interpreter.get_input_details()\n","    output_details = interpreter.get_output_details()\n","\n","    interpreter.set_tensor(input_details[0]['index'], input_data)\n","\n","    # Calcola il tempo di inferenza\n","    start_time = time.time()\n","    interpreter.invoke()\n","    end_time = time.time()\n","    inference_time = end_time - start_time\n","\n","    output_data = interpreter.get_tensor(output_details[0]['index'])\n","\n","    return output_data, inference_time\n","\n","def calculate_metrics(y_true, y_pred, y_probs):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    specificity = recall_score(y_true, y_pred, pos_label=0)\n","    fpr, tpr, thresholds = roc_curve(y_true, y_probs)\n","    roc_auc = auc(fpr, tpr)\n","\n","    return accuracy, precision, recall, specificity, roc_auc, fpr, tpr\n","\n","def plot_roc_curve(fpr, tpr, roc_auc, title='ROC Curve'):\n","    plt.figure()\n","    plt.plot(fpr, tpr, color='b', lw=2, label='ROC curve (area = %0.4f)' % roc_auc)\n","    plt.plot([0, 1], [0, 1], color='r', linestyle='--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title(title)\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","def load_videos_from_folder(folder_path, label, input_shape, batch_size):\n","    videos = []\n","    labels = []\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith(\".mp4\") or filename.endswith(\".avi\"):\n","            video_path = os.path.join(folder_path, filename)\n","            video_batches = preprocess_video(video_path, input_shape, batch_size)\n","            videos.extend(video_batches)\n","            labels.extend([label] * len(video_batches))\n","    return videos, labels\n","\n","\n","from codecarbon import track_emissions\n","@track_emissions(project_name=\"MV3_Small_Inference_BiLSTM_QAT\")\n","def inferenceV3_BiLSTM():\n","    MODEL_PATH = '/content/model_quantized.tflite'\n","    violence_path = '/content/gdrive/MyDrive/VideoInferenza/Violence'\n","    nonviolence_path = '/content/gdrive/MyDrive/VideoInferenza/NonViolence'\n","    input_shape = (224, 224)\n","    batch_size = 16\n","\n","    interpreter = load_tflite_model(MODEL_PATH)\n","\n","    violence_videos, violence_labels = load_videos_from_folder(violence_path, 1, input_shape, batch_size)\n","    nonviolence_videos, nonviolence_labels = load_videos_from_folder(nonviolence_path, 0, input_shape, batch_size)\n","\n","    all_videos = violence_videos + nonviolence_videos\n","    all_labels = violence_labels + nonviolence_labels\n","\n","    all_videos = np.array([np.expand_dims(video, axis=0) for video in all_videos])\n","    all_labels = np.array(all_labels)\n","\n","    total_inference_time = 0\n","    y_probs = []\n","    for video in all_videos:\n","        output_data, inference_time = run_inference(interpreter, video)\n","        total_inference_time += inference_time\n","        y_probs.append(output_data.ravel()[0])\n","\n","    y_probs = np.array(y_probs)\n","    y_pred = np.round(y_probs)\n","\n","    # Calculate metrics\n","    accuracy, precision, recall, specificity, roc_auc, fpr, tpr = calculate_metrics(all_labels, y_pred, y_probs)\n","\n","    # Calculate average inference time\n","    average_inference_time = total_inference_time / len(all_videos)\n","\n","    # Print metrics\n","    print(f'Accuracy: {accuracy:.4f}')\n","    print(f'Precision: {precision:.4f}')\n","    print(f'Recall: {recall:.4f}')\n","    print(f'Specificity: {specificity:.4f}')\n","    print(f'ROC AUC: {roc_auc:.4f}')\n","    print(f'Average Inference Time: {average_inference_time:.4f} seconds')\n","\n","    # Print classification report and confusion matrix\n","    print('Classification Report:')\n","    print(classification_report(all_labels, y_pred))\n","\n","    print('Confusion Matrix:')\n","    print(confusion_matrix(all_labels, y_pred))\n","\n","    # Plot ROC curve\n","    plot_roc_curve(fpr, tpr, roc_auc, title='ROC Curve for tf_model_mv3_BiLStm_QAt')\n","\n","if __name__ == '__main__':\n","    inferenceV3_BiLSTM()\n"],"metadata":{"id":"114HNajbjjqe"},"execution_count":null,"outputs":[]}]}